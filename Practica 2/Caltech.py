# -*- coding: utf-8 -*-
"""Cifar.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Ludvins/VC/blob/master/Practica%202/Keras.ipynb

## Imports
"""

import numpy as np
import keras
import matplotlib.pyplot as plt
import keras.utils as np_utils
# Import optimizer
from keras.optimizers import SGD
# Import data
from keras.datasets import cifar100
# Import models and layers
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D, Activation, BatchNormalization, Conv1D, GlobalAveragePooling2D
# Import image proprocessors
from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
# Import Resnet
from keras.applications.resnet50 import ResNet50, preprocess_input
# Import Early Stopping
from keras.callbacks import EarlyStopping
# Show no TensorFlow deprecation warnings
import tensorflow.compat.v1 as tf
tf.logging.set_verbosity(tf.logging.ERROR)

PATH = "./"
"""# Data reading functions
"""
"""## Caltech

Returns images and classes in `path_list`.
"""

def read_img (paths_list):
    classes = np.array([path.split('/')[0] for path in paths_list])
    vim = np.array([img_to_array(load_img(PATH + "images/"+ im, target_size = (224,224,3))) 
                    for im in paths_list])

    return vim, classes

"""Reads `Caltech` data in `x_train`, `y_train`, `x_test` y `y_test`"""

def load_caltech_data():

    # Load files with paths
    train_path = np.loadtxt(PATH + "lists/train.txt", dtype = str)
    test_path = np.loadtxt(PATH + "lists/test.txt", dtype = str)

    # Read imgs
    print("Loading data...")
    x_train, y_train = read_img(train_path)
    x_test, y_test = read_img(test_path)
    print("Data loaded.")

    # Set classes to numerical
    unique_classes = np.unique(np.copy(y_train))
    for i in range(len(unique_classes)):
      y_train[y_train == unique_classes[i]] = i
      y_test[y_test == unique_classes[i]] = i

    # Set classes to categorical
    y_train = np_utils.to_categorical(y_train, 200)
    y_test = np_utils.to_categorical(y_test, 200)

    # Shuffle data
    x_train_perm = np.random.permutation(len(x_train))
    x_train = x_train[x_train_perm]
    y_train = y_train[x_train_perm]

    x_test_perm = np.random.permutation(len(x_test))
    x_test = x_test[x_test_perm]
    y_test = y_test[x_test_perm]

    return x_train, y_train, x_test, y_test

"""Preprocess caltech data to be used by ResNet."""

def load_preprocessed_caltech_data():
  x_train, y_train, x_test, y_test = load_caltech_data()
  return preprocess_input(x_train), y_train, preprocess_input(x_test), y_test

"""# Functions for graphics

Draws two graphics.
+ Loss function evolution.
+ Accuracy function evolution.

Args:
+ ```hist```: Training records
"""

def show_evolution(hist):
    loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    plt.plot(loss)
    plt.plot(val_loss)
    plt.legend(['Training loss', 'Validation loss'])
    plt.show()
    
    acc = hist.history['accuracy']
    val_acc = hist.history['val_accuracy']
    plt.plot(acc)
    plt.plot(val_acc)
    plt.legend(['Training accuracy', 'Validation accuracy'])
    plt.show()

"""Draws the same graphics as ```show_evolution``` but using a list of records ```hist```."""

def compare_evolution(hist, names):

    for i in hist:
        val_loss = i.history['val_loss']
        plt.plot(val_loss)

    plt.legend(["Validation loss " + names[i] for i in range(len(hist))])
    plt.show()

    for i in hist:
        val_acc = i.history['val_accuracy']
        plt.plot(val_acc)

    plt.legend(["Validation accuracy " + names[i] for i in range(len(hist))])
    plt.show()


"""# Model definitions
"""

"""## Classifier Models"""

def basic_classifier_model():
  model = Sequential()

  model.name = "Clasificador Básico"
  model.add(Dense(200, activation='softmax', input_shape=(2048,)))
  return model

def two_layers_classifier_model():
  model = Sequential()

  model.name = "Clasificador Complejo"
  model.add(Dense(1024, activation='relu', input_shape=(2048,)))
  model.add(Dense(200, activation='softmax'))
  return model

def two_layers_dropout_classifier_model():
  model = Sequential()

  model.name = "Clasificador Complejo"
  model.add(Dense(1024, activation='relu', input_shape=(2048,)))
  model.add(Dropout(0.75))
  model.add(Dense(200, activation='softmax'))
  return model

"""## ResNet Model"""

def one_layer_resnet_model():
    resnet50 = ResNet50(weights='imagenet', include_top=False, pooling="avg", input_shape=(224,224,3))
    x = resnet50.output
    last = Dense(200, activation='softmax')(x)
    model = Model(inputs=resnet50.input, output = last)
      
    return model

def two_layers_resnet_model():
    resnet50 = ResNet50(weights='imagenet', include_top=False, pooling="avg", input_shape=(224,224,3))
    x = resnet50.output
    x = Dense(1024, activation='relu')(x)
    last = Dense(200, activation='softmax')(x)
    model = Model(inputs=resnet50.input, output = last)
      
    return model

def two_layers_conv_resnet_model():
    resnet50 = ResNet50(weights='imagenet', include_top=False, pooling=None, input_shape=(224,224,3))
    x = resnet50.output
    x = Conv2D(64, (3, 3), activation='relu')(x)
    x = Dropout(0.2)(x)
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    x = Dropout(0.4)(x)
    last = Dense(200, activation='softmax')(x)
    model = Model(inputs=resnet50.input, output = last)

    return model

"""# Training and evaluation function

Compiles the given model
"""

def model_compile(model):
    model.compile(
        loss = keras.losses.categorical_crossentropy,
        optimizer = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True),
        metrics = ['accuracy']
    )

"""Fits the datagen given by `data_generator` to the given set."""

def fitted_datagen(data_generator, x_train):
    datagen = data_generator()
    datagen.fit(x_train)

    return datagen

"""Fits the model using `train_datagen` if given."""

def train(model, x_train, y_train, batch_size, epochs, train_datagen = None, verbose = 1, val_split = 0.1, shuffle = True):

    if (verbose != 0):
      print(" - ENTRENAMIENTO - ")

    if train_datagen is None:
      return model.fit(x_train, y_train, batch_size, epochs, verbose = verbose, validation_split = val_split, shuffle = shuffle)

    else:
      return model.fit_generator(
                generator = train_datagen.flow(x_train, y_train, batch_size, subset='training'),
                steps_per_epoch = len(x_train)*0.9/batch_size,
                epochs = epochs,
                validation_data = train_datagen.flow(x_train, y_train, batch_size, subset='validation'),
                validation_steps = len(x_train)*0.1/batch_size,
                verbose = verbose,
                callbacks = [EarlyStopping(monitor = 'val_accuracy', patience = 10, restore_best_weights = True)],
                shuffle = shuffle
                )

"""Evaluates the model using `train_datagen` if given."""

def evaluate(model, x_test, y_test, test_datagen = None, verbose = 0):
    if (verbose != 0):
      print(" - RESULTADOS - ")
    if test_datagen is None:
      score = model.evaluate(x_test, y_test, verbose = verbose)
    else:
      score = model.evaluate_generator(
        generator = test_datagen.flow(x_test, y_test, 1),
        verbose = verbose
      )
    
    print('PÉRDIDA: ', score[0])
    print('PRECISIÓN: ', score[1])

"""Extracts features using the model and the`train_datagen` if given."""

def extract_features(model, data, train_datagen = None, verbose = 1):

    if train_datagen is None:
      return model.predict(data, verbose = verbose)

    return model.predict_generator(
                generator = train_datagen.flow(data, batch_size = 1, shuffle = False),
                steps = len(data),
                )

"""# Test functions

## ResNet & Caltech

### Feature extractor
"""

caltech_train, caltech_train_labels, caltech_test, caltech_test_labels = load_preprocessed_caltech_data()
resnet50 = ResNet50(weights='imagenet', include_top=False, pooling="avg", input_shape=(224,224,3))
caltech_train_features = extract_features(resnet50, caltech_train)
caltech_test_features = extract_features(resnet50, caltech_test)

def extractor():
    print(" --- RESNET EXTRACTOR DE CARACTERÍSTICAS --- ")
    basic_classifier = basic_classifier_model()
    model_compile(basic_classifier)
    h = train(basic_classifier, caltech_train_features, caltech_train_labels, 32, 20, verbose=1)

    evaluate(basic_classifier, caltech_test_features, caltech_test_labels)
    show_evolution(h)

    print(" --- RESNET EXTRACTOR DE CARACTERÍSTICAS MODELO 2 CAPAS --- ")
    classifier = two_layers_classifier_model()
    model_compile(classifier)
    h2 = train(classifier, caltech_train_features, caltech_train_labels, 32, 20, verbose = 0)

    evaluate(classifier, caltech_test_features, caltech_test_labels)
    show_evolution(h2)

    print(" --- RESNET EXTRACTOR DE CARACTERÍSTICAS MODELO COMPLEJO CON DROPOUT --- ")
    classifier = two_layers_dropout_classifier_model()
    model_compile(classifier)
    h3 = train(classifier, caltech_train_features, caltech_train_labels, 32, 30, verbose = 0)

    evaluate(classifier, caltech_test_features, caltech_test_labels)
    show_evolution(h3)
    compare_evolution([h, h2, h3], ["modelo 1 capa", "modelo 2 capas", "modelo 2 capas con dropout"])

def fine_tunning():
    print(" --- RESNET SIN CONGELAR CON UNA CAPA DENSA ---")
    m = one_layer_resnet_model()
    model_compile(m)
    h = train(m, caltech_train, caltech_train_labels, 32, 10, verbose=1)
    evaluate(m, caltech_test, caltech_test_labels)

    print(" - GRÁFICAS - ")
    show_evolution(h)

    print(" --- RESNET SIN CONGELAR CON DOS CAPAS DENSAS ----")
    m = two_layers_resnet_model()
    model_compile(m)
    #m.summary()
    h = train(m, caltech_train, caltech_train_labels, 32, 10, verbose=1)
    evaluate(m, caltech_test, caltech_test_labels)

    print(" - GRÁFICAS - ")
    show_evolution(h)

    print(" --- RESNET SIN CONGELAR CON CONVOLUCION ----")
    m = two_layers_conv_resnet_model()
    model_compile(m)
    h = train(m, caltech_train, caltech_train_labels, 32, 10, verbose=1)
    evaluate(m, caltech_test, caltech_test_labels)

    print(" - GRÁFICAS - ")
    show_evolution(h)


extractor()
fine_tunning()
