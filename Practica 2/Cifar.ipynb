{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar las librerias necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.utils as np_utils\n",
    "# Importar el optimizador a usar\n",
    "from keras.optimizers import SGD\n",
    "# Importtar el conjunto de datos\n",
    "from keras.datasets import cifar100\n",
    "# Importar modelos y capas que se van a usar\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar y modificar el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples processed before the model is updated.\n",
    "batch_size = 128\n",
    "# Ammount of classes\n",
    "num_classes = 25\n",
    "# Number of times that the learning algorithm will work through the entire training dataset.\n",
    "epochs = 12\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# input shape\n",
    "input_shape = (img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A esta función sólo se le llama una vez. Devuelve 4 vectores conteniendo, por este orden, las imágenes de entrenamiento, las clases de las imagenes de enternamiento, las imágenes del conjunto de test y las clases del conjunto de test.\n",
    "Cifar100 tiene imágenes de tamaño (32, 32, 3). Nos vamos a quedar con las imágenes de 25 de las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargarImagenes():\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    train_idx = np.isin(y_train, np.arange(25))\n",
    "    train_idx = np.reshape(train_idx, -1)\n",
    "    x_train = x_train[train_idx]\n",
    "    y_train = y_train[train_idx]\n",
    "    test_idx = np.isin(y_test, np.arange(25))\n",
    "    test_idx = np.reshape(test_idx, -1)\n",
    "    x_test = x_test[test_idx]\n",
    "    y_test = y_test[test_idx]\n",
    "    \n",
    "    '''\n",
    "    Transformamos los vectores de clases en matrices.\n",
    "    Cada componente se convierte en un vector de ceros con un uno en la componente correspondiente a la clase a la que pertenece la imagen.\n",
    "    Este paso es necesario para la clasificación multiclase en keras.\n",
    "    '''\n",
    "    \n",
    "    y_train = np_utils.to_categorical(y_train, 25)\n",
    "    y_test = np_utils.to_categorical(y_test, 25)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener el accuracy en el conjunto de test\n",
    "\n",
    "Esta función devuelve el accuracy de un modelo, definido como el porcentaje de etiquetas bien predichas frente al total de etiquetas. Como parámetros es necesario pasarle el vector de etiquetas verdaderas y el vector de etiquedas predichas, en el formato de keras (matrices donde cada etiqueta ocupa una fila, con un 1 en laposición de la clase a la que pertenece y 0 en las demás)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcularAccuracy(labels, preds):\n",
    "    labels = np.argmax(labels, axis = 1)\n",
    "    preds = np.argmas(preds, axis = 1)\n",
    "    \n",
    "    return sum(labels==preds)/len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función pintar la pérdida y el accuracy en train y validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función pinta dos gráficas, una con la evolución de la función de pérdida en el conjunto de train y en el de validación, y otra con la evolución del accuracy en el conjunto de train y el de validación.\n",
    "es necesario pasarle como parámetro el historial del entrenamiento del modelo (lo devuelven las funciones fit() y fit_generator())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarEvolucion(hist):\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.legend(['Training loss', 'Validation loss'])\n",
    "    plt.show()\n",
    "    \n",
    "    hcc = hist.history['accuracy']\n",
    "    val_acc = hist.history['val_accuracy']\n",
    "    plt.plot(acc)\n",
    "    plt.plot(val_acc)\n",
    "    plt.legend(['Training accuracy', 'Validation accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo BaseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 28)        2128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 28)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 10)        7010      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                12550     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "=================================================================\n",
      "Total params: 22,963\n",
      "Trainable params: 22,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(5, 5),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(10, kernel_size=(5,5), \n",
    "                activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion del optimizador y compilacion del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configures the model for training.\n",
    "\n",
    "+ **optimizer:** String (name of optimizer) or optimizer instance.\n",
    "+ **loss:** String (name of objective function) or objective function or Loss instance.\n",
    "+ **metrics:** List of metrics to be evaluated by the model during training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "              optimizer = SGD(lr = 0.01, decay = 1e-6, momentum=0.9, nesterov=True),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos el modelo base, y antes de entrenar, vamos a guardar los pesos aleatorios con los que empieza la red, para poder reestablecerlos después y comparar resultados entre no usar mejoras y sí usarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trains the model for a fixed number of epochs (iterations on a dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12500 samples, validate on 2500 samples\n",
      "Epoch 1/12\n",
      " 1024/12500 [=>............................] - ETA: 7s - loss: 3.2253 - accuracy: 0.0361"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = cargarImagenes()\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "mostrarEvolucion(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejora del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto la normalización de los datos como el data augmentation debe hacerse con la clase ImageDataGenerator.\n",
    "Se recomienda ir entrenando con cada paso para comprobar en qué grado mejora cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "802px",
    "left": "1210px",
    "top": "113px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
